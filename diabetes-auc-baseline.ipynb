{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91723,"databundleVersionId":14272474,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nRANDOM_STATE = 42\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:42.939952Z","iopub.execute_input":"2025-12-18T03:18:42.940388Z","iopub.status.idle":"2025-12-18T03:18:46.544680Z","shell.execute_reply.started":"2025-12-18T03:18:42.940337Z","shell.execute_reply":"2025-12-18T03:18:46.543715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Load data\nTRAIN_PATH = 'train.csv'\nTEST_PATH = 'test.csv'\n\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s5e12/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e12/test.csv\")\n\nprint('train shape:', train_df.shape)\nprint('test shape :', test_df.shape)\ndisplay(train_df.head())\ndisplay(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:46.546884Z","iopub.execute_input":"2025-12-18T03:18:46.547312Z","iopub.status.idle":"2025-12-18T03:18:49.775865Z","shell.execute_reply.started":"2025-12-18T03:18:46.547279Z","shell.execute_reply":"2025-12-18T03:18:49.775081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2) Define features/target\nTARGET_COL = 'diagnosed_diabetes'\nID_COL = 'id'\n\nX = train_df.drop(columns=[TARGET_COL])\ny = train_df[TARGET_COL].astype(int)\n\nprint('Target positive rate:', y.mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:49.776999Z","iopub.execute_input":"2025-12-18T03:18:49.777325Z","iopub.status.idle":"2025-12-18T03:18:49.872405Z","shell.execute_reply.started":"2025-12-18T03:18:49.777291Z","shell.execute_reply":"2025-12-18T03:18:49.871564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3) Identify numeric vs categorical columns\n# NOTE: Some datasets store categoricals as strings; others store them as integer codes.\n# We handle both by explicitly listing the known categorical feature names.\nknown_categoricals = [\n    'gender',\n    'ethnicity',\n    'education_level',\n    'income_level',\n    'smoking_status',\n    'employment_status',\n]\n\ncategorical_cols = X.select_dtypes(include=['object']).columns.tolist()\nfor c in known_categoricals:\n    if c in X.columns and c not in categorical_cols:\n        categorical_cols.append(c)\n\nnumeric_cols = [c for c in X.columns if c not in categorical_cols]\n\nprint('Categorical columns:', categorical_cols)\nprint('Numeric columns     :', numeric_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:49.873557Z","iopub.execute_input":"2025-12-18T03:18:49.873899Z","iopub.status.idle":"2025-12-18T03:18:49.930160Z","shell.execute_reply.started":"2025-12-18T03:18:49.873865Z","shell.execute_reply":"2025-12-18T03:18:49.929249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4) Build a baseline pipeline\n# - Impute missing values\n# - One-hot encode categoricals (handle unseen categories in test)\n# - Scale numerics (with_mean=False so it stays compatible with sparse matrices)\n# - Train Logistic Regression (fast, strong baseline for tabular problems)\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler(with_mean=False)),\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n])\n\npreprocess = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols),\n    ],\n    remainder='drop',\n)\n\nmodel = LogisticRegression(\n    solver='saga',\n    max_iter=200,\n    n_jobs=-1,\n)\n\nclf = Pipeline(steps=[('preprocess', preprocess), ('model', model)])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:49.931345Z","iopub.execute_input":"2025-12-18T03:18:49.931668Z","iopub.status.idle":"2025-12-18T03:18:49.938051Z","shell.execute_reply.started":"2025-12-18T03:18:49.931605Z","shell.execute_reply":"2025-12-18T03:18:49.937258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5) Quick local validation (train/valid split)\n# This gives you a rough idea of model quality before you train on all data.\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n)\n\nclf.fit(X_train, y_train)\nvalid_pred = clf.predict_proba(X_valid)[:, 1]\nauc = roc_auc_score(y_valid, valid_pred)\nprint(f'Validation AUC: {auc:.5f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:18:49.938965Z","iopub.execute_input":"2025-12-18T03:18:49.939803Z","iopub.status.idle":"2025-12-18T03:19:08.920513Z","shell.execute_reply.started":"2025-12-18T03:18:49.939776Z","shell.execute_reply":"2025-12-18T03:19:08.919774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6) Train on full training data and write submission.csv\nclf.fit(X, y)\ntest_pred = clf.predict_proba(test_df)[:, 1]\n\nsubmission = pd.DataFrame({\n    ID_COL: test_df[ID_COL],\n    TARGET_COL: test_pred,\n})\n\n# Sanity checks\nassert submission.columns.tolist() == [ID_COL, TARGET_COL]\nassert submission[TARGET_COL].between(0, 1).all()\n\nSUBMISSION_PATH = 'submission.csv'\nsubmission.to_csv(SUBMISSION_PATH, index=False)\nprint('Wrote', SUBMISSION_PATH, 'with shape', submission.shape)\ndisplay(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:19:08.922424Z","iopub.execute_input":"2025-12-18T03:19:08.923244Z","iopub.status.idle":"2025-12-18T03:19:29.507477Z","shell.execute_reply.started":"2025-12-18T03:19:08.923208Z","shell.execute_reply":"2025-12-18T03:19:29.506687Z"}},"outputs":[],"execution_count":null}]}